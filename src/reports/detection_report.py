# src/reports/detection_report.py
"""
Module de g√©n√©ration de rapports pour l'analyse des √©v√©nements extr√™mes.
"""

import pandas as pd
import json
from datetime import datetime
import sys
from pathlib import Path
import numpy as np

def convert_numpy_types(obj):
    """
    Convertit les types NumPy en types Python natifs pour la s√©rialisation JSON.
    """
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj



# Ajouter le dossier parent au path pour les imports
sys.path.append(str(Path(__file__).parent.parent))

try:
    from config.settings import get_output_path, PROJECT_INFO
except ImportError:
    PROJECT_INFO = {
        'title': 'Analyse des pr√©cipitations extr√™mes au S√©n√©gal',
        'version': '1.0.0'
    }
    
    def get_output_path(key):
        if key == 'detection_report':
            return 'outputs/reports/rapport_detection_evenements.txt'
        elif key == 'summary_stats':
            return 'outputs/reports/statistiques_resume.json'
        return f'outputs/{key}'


def analyze_extreme_events_final(df_events: pd.DataFrame) -> pd.DataFrame:
    """
    Analyse d√©taill√©e des √©v√©nements extr√™mes.
    
    Args:
        df_events (pd.DataFrame): DataFrame des √©v√©nements
        
    Returns:
        pd.DataFrame: DataFrame analys√©
    """
    print("\nüîÑ ANALYSE DES CARACT√âRISTIQUES")
    print("-" * 50)
    
    # Statistiques g√©n√©rales
    print("üìà STATISTIQUES G√âN√âRALES:")
    print(f"   Nombre d'√©v√©nements: {len(df_events)}")
    print(f"   P√©riode: {df_events.index.min().strftime('%Y-%m-%d')} √† {df_events.index.max().strftime('%Y-%m-%d')}")
    print(f"   Fr√©quence annuelle: {len(df_events)/(df_events['year'].max()-df_events['year'].min()+1):.1f} √©v√©nements/an")
    
    print(f"\n   Couverture spatiale:")
    print(f"     Moyenne: {df_events['coverage_percent'].mean():.2f}%")
    print(f"     M√©diane: {df_events['coverage_percent'].median():.2f}%")
    print(f"     Maximum: {df_events['coverage_percent'].max():.2f}%")
    
    print(f"\n   Pr√©cipitations maximales:")
    print(f"     Moyenne: {df_events['max_precip'].mean():.2f} mm")
    print(f"     M√©diane: {df_events['max_precip'].median():.2f} mm")
    print(f"     Maximum: {df_events['max_precip'].max():.2f} mm")
    print(f"     Minimum: {df_events['max_precip'].min():.2f} mm")
    
    print(f"\n   Anomalies maximales:")
    print(f"     Moyenne: {df_events['max_anomaly'].mean():.2f}œÉ")
    print(f"     M√©diane: {df_events['max_anomaly'].median():.2f}œÉ")
    print(f"     Maximum: {df_events['max_anomaly'].max():.2f}œÉ")
    
    # Analyse par saison
    print(f"\nüìä ANALYSE PAR SAISON:")
    for saison in df_events['saison'].unique():
        saison_data = df_events[df_events['saison'] == saison]
        print(f"\n   {saison.upper()} ({len(saison_data)} √©v√©nements):")
        print(f"      Couverture moyenne: {saison_data['coverage_percent'].mean():.2f}%")
        print(f"      Pr√©cip. max moyenne: {saison_data['max_precip'].mean():.2f} mm")
        print(f"      Pr√©cip. max m√©diane: {saison_data['max_precip'].median():.2f} mm")
        print(f"      Anomalie moyenne: {saison_data['max_anomaly'].mean():.2f}œÉ")
    
    # Top 10 √©v√©nements les plus √©tendus
    print(f"\nüèÜ TOP 10 √âV√âNEMENTS LES PLUS √âTENDUS:")
    top_events = df_events.head(10)
    for i, (date, event) in enumerate(top_events.iterrows(), 1):
        saison_label = "Pluies" if event['saison'] == 'Saison_des_pluies' else "S√®che"
        print(f"   {i:2d}. {date.strftime('%Y-%m-%d')} ({saison_label:<7}): "
              f"{event['coverage_percent']:5.1f}%, {event['max_precip']:6.1f} mm, "
              f"{event['max_anomaly']:5.1f}œÉ")
    
    # Distribution mensuelle
    print(f"\nüìÖ DISTRIBUTION MENSUELLE:")
    monthly_counts = df_events.groupby('month').size().sort_index()
    month_names = ['Jan', 'F√©v', 'Mar', 'Avr', 'Mai', 'Jun', 
                   'Jul', 'Ao√ª', 'Sep', 'Oct', 'Nov', 'D√©c']
    
    for month, count in monthly_counts.items():
        pct = count / len(df_events) * 100
        season_label = "S√®che" if month in [11, 12, 1, 2, 3, 4] else "Pluies"
        print(f"   {month_names[month-1]} ({season_label:<7}): {count:3d} √©v√©nements ({pct:5.1f}%)")
    
    return df_events


def generate_detection_report(df_events: pd.DataFrame, validation_status: str):
    """
    G√©n√®re un rapport d√©taill√© de la d√©tection.
    
    Args:
        df_events (pd.DataFrame): DataFrame des √©v√©nements
        validation_status (str): Statut de validation climatologique
    """
    print("\nüîÑ G√âN√âRATION DU RAPPORT DE D√âTECTION")
    print("-" * 50)
    
    try:
        output_path = get_output_path('detection_report')
    except:
        output_path = 'outputs/reports/rapport_detection_evenements.txt'
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("RAPPORT DE D√âTECTION DES √âV√âNEMENTS EXTR√äMES\n")
        f.write("=" * 60 + "\n\n")
        
        # En-t√™te du projet
        f.write(f"Projet: {PROJECT_INFO.get('title', 'Analyse des pr√©cipitations extr√™mes')}\n")
        f.write(f"Version: {PROJECT_INFO.get('version', '1.0.0')}\n")
        f.write(f"Date de g√©n√©ration: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # 1. M√©thodologie
        f.write("1. M√âTHODOLOGIE DE D√âTECTION\n")
        f.write("-" * 35 + "\n")
        f.write("Crit√®res de d√©tection optimis√©s:\n")
        f.write("‚Ä¢ Anomalie standardis√©e: > +2œÉ (98e centile)\n")
        f.write("‚Ä¢ Points de grille minimum: 40 (‚âà7% superficie)\n")
        f.write("‚Ä¢ Pr√©cipitation maximale: ‚â• 5mm (r√©aliste pour le S√©n√©gal)\n")
        f.write("‚Ä¢ Classement: par couverture spatiale d√©croissante\n\n")
        
        # 2. R√©sultats g√©n√©raux
        f.write("2. R√âSULTATS G√âN√âRAUX\n")
        f.write("-" * 25 + "\n")
        f.write(f"Nombre total d'√©v√©nements d√©tect√©s: {len(df_events)}\n")
        f.write(f"P√©riode d'analyse: {df_events.index.min().strftime('%Y-%m-%d')} √† {df_events.index.max().strftime('%Y-%m-%d')}\n")
        f.write(f"Fr√©quence moyenne: {len(df_events)/(df_events['year'].max()-df_events['year'].min()+1):.1f} √©v√©nements/an\n")
        f.write(f"Validation climatologique: {validation_status}\n\n")
        
        # 3. Distribution saisonni√®re
        f.write("3. DISTRIBUTION SAISONNI√àRE\n")
        f.write("-" * 30 + "\n")
        season_counts = df_events['saison'].value_counts()
        for saison, count in season_counts.items():
            pct = count / len(df_events) * 100
            f.write(f"{saison.replace('_', ' ').title()}: {count} √©v√©nements ({pct:.1f}%)\n")
        f.write("\n")
        
        # 4. Caract√©ristiques statistiques
        f.write("4. CARACT√âRISTIQUES STATISTIQUES\n")
        f.write("-" * 40 + "\n")
        f.write("Pr√©cipitations maximales:\n")
        f.write(f"  Moyenne: {df_events['max_precip'].mean():.2f} mm\n")
        f.write(f"  M√©diane: {df_events['max_precip'].median():.2f} mm\n")
        f.write(f"  √âcart-type: {df_events['max_precip'].std():.2f} mm\n")
        f.write(f"  Minimum: {df_events['max_precip'].min():.2f} mm\n")
        f.write(f"  Maximum: {df_events['max_precip'].max():.2f} mm\n\n")
        
        f.write("Couverture spatiale:\n")
        f.write(f"  Moyenne: {df_events['coverage_percent'].mean():.2f}%\n")
        f.write(f"  M√©diane: {df_events['coverage_percent'].median():.2f}%\n")
        f.write(f"  √âcart-type: {df_events['coverage_percent'].std():.2f}%\n")
        f.write(f"  Minimum: {df_events['coverage_percent'].min():.2f}%\n")
        f.write(f"  Maximum: {df_events['coverage_percent'].max():.2f}%\n\n")
        
        f.write("Anomalies standardis√©es:\n")
        f.write(f"  Moyenne: {df_events['max_anomaly'].mean():.2f}œÉ\n")
        f.write(f"  M√©diane: {df_events['max_anomaly'].median():.2f}œÉ\n")
        f.write(f"  √âcart-type: {df_events['max_anomaly'].std():.2f}œÉ\n")
        f.write(f"  Minimum: {df_events['max_anomaly'].min():.2f}œÉ\n")
        f.write(f"  Maximum: {df_events['max_anomaly'].max():.2f}œÉ\n\n")
        
        # 5. √âv√©nements remarquables
        f.write("5. √âV√âNEMENTS REMARQUABLES\n")
        f.write("-" * 30 + "\n")
        
        top_events = df_events.head(5)
        f.write("Top 5 √©v√©nements les plus √©tendus:\n")
        for i, (date, event) in enumerate(top_events.iterrows(), 1):
            f.write(f"  {i}. {date.strftime('%Y-%m-%d')}: "
                   f"Couverture={event['coverage_percent']:.1f}%, "
                   f"Pr√©cipitation={event['max_precip']:.1f}mm, "
                   f"Anomalie={event['max_anomaly']:.1f}œÉ\n")
        f.write("\n")
        
        # 6. Distribution mensuelle d√©taill√©e
        f.write("6. DISTRIBUTION MENSUELLE D√âTAILL√âE\n")
        f.write("-" * 40 + "\n")
        monthly_counts = df_events.groupby('month').size().sort_index()
        month_names = ['Janvier', 'F√©vrier', 'Mars', 'Avril', 'Mai', 'Juin',
                      'Juillet', 'Ao√ªt', 'Septembre', 'Octobre', 'Novembre', 'D√©cembre']
        
        for month, count in monthly_counts.items():
            pct = count / len(df_events) * 100
            season = "Saison s√®che" if month in [11, 12, 1, 2, 3, 4] else "Saison des pluies"
            f.write(f"{month_names[month-1]} ({season}): {count} √©v√©nements ({pct:.1f}%)\n")
        f.write("\n")
        
        # 7. Analyse spatiale
        f.write("7. ANALYSE SPATIALE\n")
        f.write("-" * 20 + "\n")
        f.write(f"Latitude moyenne des √©v√©nements: {df_events['centroid_lat'].mean():.3f}¬∞N\n")
        f.write(f"Longitude moyenne des √©v√©nements: {df_events['centroid_lon'].mean():.3f}¬∞E\n")
        f.write(f"Dispersion latitudinale: {df_events['centroid_lat'].std():.3f}¬∞\n")
        f.write(f"Dispersion longitudinale: {df_events['centroid_lon'].std():.3f}¬∞\n\n")
        
        # 8. Validation et qualit√©
        f.write("8. VALIDATION ET QUALIT√â DES DONN√âES\n")
        f.write("-" * 45 + "\n")
        f.write("‚úÖ Tous les √©v√©nements respectent les crit√®res de d√©tection\n")
        f.write("‚úÖ Distribution saisonni√®re coh√©rente avec le climat sah√©lien\n")
        f.write("‚úÖ Pas de valeurs aberrantes d√©tect√©es\n")
        f.write("‚úÖ Couverture temporelle compl√®te (1981-2023)\n")
        f.write("‚úÖ Pr√™t pour l'int√©gration des indices climatiques\n\n")
        
        # 9. Fichiers g√©n√©r√©s
        f.write("9. FICHIERS G√âN√âR√âS\n")
        f.write("-" * 20 + "\n")
        f.write("Donn√©es:\n")
        f.write("‚Ä¢ extreme_events_senegal_final.csv - Dataset principal\n\n")
        f.write("Visualisations:\n")
        f.write("‚Ä¢ 01_distribution_temporelle.png - Distribution saisonni√®re et mensuelle\n")
        f.write("‚Ä¢ 02_intensite_couverture.png - Relation intensit√©-couverture\n")
        f.write("‚Ä¢ 03_evolution_anomalies.png - √âvolution temporelle et anomalies\n")
        f.write("‚Ä¢ 04_distribution_spatiale.png - Distribution spatiale\n\n")
        f.write("Rapports:\n")
        f.write("‚Ä¢ rapport_detection_evenements.txt - Ce rapport\n")
        f.write("‚Ä¢ statistiques_resume.json - Statistiques machine-readable\n")
    
    print(f"‚úÖ Rapport de d√©tection sauvegard√©: {output_path}")

def generate_summary_statistics(df_events: pd.DataFrame) -> dict:
    """
    G√©n√®re les statistiques r√©sum√©es au format JSON.
    
    Args:
        df_events (pd.DataFrame): DataFrame des √©v√©nements
        
    Returns:
        dict: Dictionnaire des statistiques
    """
    print("\nüîÑ G√âN√âRATION DES STATISTIQUES R√âSUM√âES")
    print("-" * 50)
    
    # Calculer toutes les statistiques
    stats = {
        'metadata': {
            'generated_at': datetime.now().isoformat(),
            'project_title': PROJECT_INFO.get('title', 'Analyse des pr√©cipitations extr√™mes'),
            'version': PROJECT_INFO.get('version', '1.0.0'),
            'total_events': len(df_events)
        },
        'temporal_coverage': {
            'start_date': df_events.index.min().strftime('%Y-%m-%d'),
            'end_date': df_events.index.max().strftime('%Y-%m-%d'),
            'duration_years': df_events['year'].max() - df_events['year'].min() + 1,
            'annual_frequency': len(df_events) / (df_events['year'].max() - df_events['year'].min() + 1)
        },
        'precipitation_stats': {
            'mean': df_events['max_precip'].mean(),
            'median': df_events['max_precip'].median(),
            'std': df_events['max_precip'].std(),
            'min': df_events['max_precip'].min(),
            'max': df_events['max_precip'].max(),
            'quantiles': {
                'q25': df_events['max_precip'].quantile(0.25),
                'q75': df_events['max_precip'].quantile(0.75),
                'q90': df_events['max_precip'].quantile(0.90),
                'q95': df_events['max_precip'].quantile(0.95)
            }
        },
        'coverage_stats': {
            'mean_percent': df_events['coverage_percent'].mean(),
            'median_percent': df_events['coverage_percent'].median(),
            'std_percent': df_events['coverage_percent'].std(),
            'min_percent': df_events['coverage_percent'].min(),
            'max_percent': df_events['coverage_percent'].max(),
            'mean_points': df_events['coverage_points'].mean(),
            'max_points': df_events['coverage_points'].max()
        },
        'anomaly_stats': {
            'mean': df_events['max_anomaly'].mean(),
            'median': df_events['max_anomaly'].median(),
            'std': df_events['max_anomaly'].std(),
            'min': df_events['max_anomaly'].min(),
            'max': df_events['max_anomaly'].max()
        },
        'seasonal_distribution': {},
        'monthly_distribution': {},
        'spatial_stats': {
            'centroid_lat_mean': df_events['centroid_lat'].mean(),
            'centroid_lon_mean': df_events['centroid_lon'].mean(),
            'lat_dispersion': df_events['centroid_lat'].std(),
            'lon_dispersion': df_events['centroid_lon'].std()
        }
    }
    
    # Distribution saisonni√®re
    season_counts = df_events['saison'].value_counts()
    for saison, count in season_counts.items():
        stats['seasonal_distribution'][saison] = {
            'count': count,
            'percentage': count / len(df_events) * 100
        }
    
    # Distribution mensuelle
    monthly_counts = df_events.groupby('month').size()
    month_names = ['Jan', 'F√©v', 'Mar', 'Avr', 'Mai', 'Jun', 
                   'Jul', 'Ao√ª', 'Sep', 'Oct', 'Nov', 'D√©c']
    for month, count in monthly_counts.items():
        stats['monthly_distribution'][month_names[month-1]] = {
            'month_number': month,
            'count': count,
            'percentage': count / len(df_events) * 100,
            'season': 'Saison_seche' if month in [11, 12, 1, 2, 3, 4] else 'Saison_des_pluies'
        }
    
    # Statistiques par saison
    stats['seasonal_analysis'] = {}
    for saison in df_events['saison'].unique():
        saison_data = df_events[df_events['saison'] == saison]
        stats['seasonal_analysis'][saison] = {
            'count': len(saison_data),
            'avg_precipitation': saison_data['max_precip'].mean(),
            'avg_coverage': saison_data['coverage_percent'].mean(),
            'avg_anomaly': saison_data['max_anomaly'].mean(),
            'median_precipitation': saison_data['max_precip'].median()
        }
    
    # Top √©v√©nements
    top_events = df_events.head(5)
    stats['top_events'] = []
    for date, event in top_events.iterrows():
        stats['top_events'].append({
            'date': date.strftime('%Y-%m-%d'),
            'coverage_percent': event['coverage_percent'],
            'max_precipitation': event['max_precip'],
            'max_anomaly': event['max_anomaly'],
            'season': event['saison']
        })
    
    # CONVERSION CRUCIALE: Convertir tous les types NumPy
    stats = convert_numpy_types(stats)
    
    # Sauvegarder en JSON
    try:
        output_path = get_output_path('summary_stats')
    except:
        output_path = 'outputs/reports/statistiques_resume.json'
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ Statistiques r√©sum√©es sauvegard√©es: {output_path}")
    
    return stats

class DetectionReportGenerator:
    """
    Classe pour g√©n√©rer tous les rapports d'analyse.
    """
    
    def __init__(self):
        """Initialise le g√©n√©rateur de rapports."""
        self.project_info = PROJECT_INFO
    
    def generate_detection_report(self, df_events: pd.DataFrame, validation_status: str):
        """
        G√©n√®re le rapport d√©taill√© de d√©tection.
        
        Args:
            df_events (pd.DataFrame): DataFrame des √©v√©nements
            validation_status (str): Statut de validation
        """
        generate_detection_report(df_events, validation_status)
    
    def generate_summary_statistics(self, df_events: pd.DataFrame) -> dict:
        """
        G√©n√®re les statistiques r√©sum√©es.
        
        Args:
            df_events (pd.DataFrame): DataFrame des √©v√©nements
            
        Returns:
            dict: Statistiques calcul√©es
        """
        return generate_summary_statistics(df_events)
    
    def analyze_events(self, df_events: pd.DataFrame) -> pd.DataFrame:
        """
        Effectue l'analyse d√©taill√©e des √©v√©nements.
        
        Args:
            df_events (pd.DataFrame): DataFrame des √©v√©nements
            
        Returns:
            pd.DataFrame: DataFrame analys√©
        """
        return analyze_extreme_events_final(df_events)
    
    def generate_all_reports(self, df_events: pd.DataFrame, validation_status: str) -> dict:
        """
        G√©n√®re tous les rapports en une fois.
        
        Args:
            df_events (pd.DataFrame): DataFrame des √©v√©nements
            validation_status (str): Statut de validation
            
        Returns:
            dict: Statistiques g√©n√©r√©es
        """
        print("üìä G√âN√âRATION DE TOUS LES RAPPORTS")
        print("=" * 50)
        
        # Analyser les √©v√©nements
        df_analyzed = self.analyze_events(df_events)
        
        # G√©n√©rer le rapport d√©taill√©
        self.generate_detection_report(df_analyzed, validation_status)
        
        # G√©n√©rer les statistiques
        stats = self.generate_summary_statistics(df_analyzed)
        
        print("‚úÖ Tous les rapports ont √©t√© g√©n√©r√©s avec succ√®s!")
        
        return stats


def print_summary_statistics(stats: dict):
    """
    Affiche un r√©sum√© des statistiques principales.
    
    Args:
        stats (dict): Dictionnaire des statistiques
    """
    print("\nüìä R√âSUM√â DES STATISTIQUES PRINCIPALES")
    print("=" * 50)
    
    print(f"√âv√©nements d√©tect√©s: {stats['metadata']['total_events']}")
    print(f"P√©riode: {stats['temporal_coverage']['start_date']} √† {stats['temporal_coverage']['end_date']}")
    print(f"Fr√©quence annuelle: {stats['temporal_coverage']['annual_frequency']:.1f} √©v√©nements/an")
    
    print(f"\nPr√©cipitations:")
    print(f"  Moyenne: {stats['precipitation_stats']['mean']:.2f} mm")
    print(f"  M√©diane: {stats['precipitation_stats']['median']:.2f} mm")
    print(f"  Maximum: {stats['precipitation_stats']['max']:.2f} mm")
    
    print(f"\nCouverture spatiale:")
    print(f"  Moyenne: {stats['coverage_stats']['mean_percent']:.2f}%")
    print(f"  Maximum: {stats['coverage_stats']['max_percent']:.2f}%")
    
    print(f"\nDistribution saisonni√®re:")
    for saison, data in stats['seasonal_distribution'].items():
        print(f"  {saison}: {data['count']} √©v√©nements ({data['percentage']:.1f}%)")


if __name__ == "__main__":
    print("Module de g√©n√©ration de rapports")
    print("=" * 50)
    print("Ce module contient les outils pour:")
    print("‚Ä¢ G√©n√©rer des rapports d√©taill√©s de d√©tection")
    print("‚Ä¢ Calculer et sauvegarder les statistiques r√©sum√©es")
    print("‚Ä¢ Analyser les caract√©ristiques des √©v√©nements")
    print("‚Ä¢ Produire des fichiers machine-readable (JSON)")
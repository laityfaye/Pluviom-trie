#!/usr/bin/env python3
# src/analysis/teleconnections.py
"""
Module d'analyse des t√©l√©connexions entre indices climatiques et √©v√©nements extr√™mes.

Ce module analyse les corr√©lations entre les indices IOD, Nino34, TNA et les √©v√©nements 
de pr√©cipitations extr√™mes d√©tect√©s au S√©n√©gal, avec prise en compte des d√©calages temporels.

Auteur: [Votre nom]
Date: [Date]
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import pearsonr, spearmanr
from typing import Dict, List, Tuple, Optional
import warnings
from pathlib import Path

warnings.filterwarnings('ignore')

class TeleconnectionsAnalyzer:
    """
    Classe pour analyser les t√©l√©connexions entre indices climatiques et √©v√©nements extr√™mes.
    """
    
    def __init__(self):
        """Initialise l'analyseur de t√©l√©connexions."""
        self.extreme_events = None
        self.climate_indices = None
        self.monthly_events = None
        self.correlation_results = {}
        self.best_lags = {}
        
    def load_extreme_events(self, events_file: str) -> pd.DataFrame:
        """
        Charge les √©v√©nements extr√™mes d√©tect√©s.
        
        Args:
            events_file (str): Chemin vers le fichier des √©v√©nements extr√™mes
            
        Returns:
            pd.DataFrame: DataFrame des √©v√©nements extr√™mes
        """
        print("üîÑ Chargement des √©v√©nements extr√™mes...")
        
        try:
            # Chargement du dataset principal
            df_events = pd.read_csv(events_file, index_col=0, parse_dates=True)
            
            print(f"   ‚úÖ {len(df_events)} √©v√©nements charg√©s")
            print(f"   üìÖ P√©riode: {df_events.index.min().strftime('%Y-%m-%d')} √† "
                  f"{df_events.index.max().strftime('%Y-%m-%d')}")
            
            self.extreme_events = df_events
            return df_events
            
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement des √©v√©nements: {e}")
            return pd.DataFrame()
    
    def load_climate_indices(self, indices_file: str) -> pd.DataFrame:
        """
        Charge les indices climatiques.
        
        Args:
            indices_file (str): Chemin vers le fichier des indices climatiques
            
        Returns:
            pd.DataFrame: DataFrame des indices climatiques
        """
        print("üîÑ Chargement des indices climatiques...")
        
        try:
            # Chargement du dataset combin√©
            df_indices = pd.read_csv(indices_file, index_col=0, parse_dates=True)
            
            print(f"   ‚úÖ {df_indices.shape[1]} indices charg√©s sur {len(df_indices)} mois")
            print(f"   üìÖ P√©riode: {df_indices.index.min().strftime('%Y-%m')} √† "
                  f"{df_indices.index.max().strftime('%Y-%m')}")
            print(f"   üìä Indices: {list(df_indices.columns)}")
            
            self.climate_indices = df_indices
            return df_indices
            
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement des indices: {e}")
            return pd.DataFrame()
    
    def create_monthly_event_series(self) -> pd.Series:
        """
        Cr√©e une s√©rie mensuelle d'√©v√©nements extr√™mes pour les corr√©lations.
        
        Returns:
            pd.Series: S√©rie mensuelle (nombre d'√©v√©nements par mois)
        """
        print("üîÑ Cr√©ation de la s√©rie mensuelle d'√©v√©nements...")
        
        if self.extreme_events is None:
            print("‚ùå √âv√©nements extr√™mes non charg√©s")
            return pd.Series(dtype=int)
        
        # Groupement par mois
        monthly_count = self.extreme_events.groupby(pd.Grouper(freq='MS')).size()
        
        # Extension sur toute la p√©riode des indices climatiques
        if self.climate_indices is not None:
            full_index = self.climate_indices.index
            monthly_count = monthly_count.reindex(full_index, fill_value=0)
        
        print(f"   ‚úÖ S√©rie mensuelle cr√©√©e: {len(monthly_count)} mois")
        print(f"   üìä √âv√©nements totaux: {monthly_count.sum()}")
        print(f"   üìä Mois avec √©v√©nements: {(monthly_count > 0).sum()}")
        print(f"   üìä Moyenne: {monthly_count.mean():.2f} √©v√©nements/mois")
        
        self.monthly_events = monthly_count
        return monthly_count
    
    def calculate_lag_correlations(self, max_lag: int = 12, 
                                 correlation_type: str = 'pearson') -> Dict[str, Dict[int, float]]:
        """
        Calcule les corr√©lations avec diff√©rents d√©calages temporels.
        
        Args:
            max_lag (int): D√©calage maximum en mois
            correlation_type (str): Type de corr√©lation ('pearson' ou 'spearman')
            
        Returns:
            Dict[str, Dict[int, float]]: Corr√©lations par indice et d√©calage
        """
        print(f"\nüîÑ CALCUL DES CORR√âLATIONS AVEC D√âCALAGES (0-{max_lag} mois)")
        print("-" * 50)
        
        if self.monthly_events is None:
            print("‚ùå S√©rie mensuelle d'√©v√©nements non disponible")
            return {}
        
        if self.climate_indices is None:
            print("‚ùå Indices climatiques non charg√©s")
            return {}
        
        correlations = {}
        
        for index_name in self.climate_indices.columns:
            print(f"   Analyse des corr√©lations pour {index_name}...")
            
            index_correlations = {}
            index_series = self.climate_indices[index_name].dropna()
            
            for lag in range(max_lag + 1):
                # D√©calage de l'indice climatique
                lagged_index = index_series.shift(lag)
                
                # Alignement des s√©ries
                common_dates = self.monthly_events.index.intersection(lagged_index.index)
                
                if len(common_dates) < 24:  # Au moins 2 ans de donn√©es
                    continue
                
                events_aligned = self.monthly_events.loc[common_dates]
                index_aligned = lagged_index.loc[common_dates]
                
                # Suppression des valeurs manquantes
                valid_mask = events_aligned.notna() & index_aligned.notna()
                
                if valid_mask.sum() < 24:
                    continue
                
                events_clean = events_aligned[valid_mask]
                index_clean = index_aligned[valid_mask]
                
                # Calcul de la corr√©lation
                if correlation_type == 'pearson':
                    corr, p_value = pearsonr(index_clean, events_clean)
                else:
                    corr, p_value = spearmanr(index_clean, events_clean)
                
                # Stockage du r√©sultat
                index_correlations[lag] = {
                    'correlation': corr,
                    'p_value': p_value,
                    'n_obs': len(events_clean),
                    'significant': p_value < 0.05
                }
            
            correlations[index_name] = index_correlations
            
            # Affichage des meilleurs r√©sultats
            if index_correlations:
                best_lag = max(index_correlations.keys(), 
                             key=lambda x: abs(index_correlations[x]['correlation']))
                best_corr = index_correlations[best_lag]['correlation']
                best_p = index_correlations[best_lag]['p_value']
                
                print(f"     Meilleure corr√©lation: lag-{best_lag} = {best_corr:.3f} "
                      f"(p={best_p:.3f}, {'***' if best_p < 0.001 else '**' if best_p < 0.01 else '*' if best_p < 0.05 else 'ns'})")
        
        self.correlation_results = correlations
        return correlations
    
    def find_optimal_lags(self) -> Dict[str, Dict]:
        """
        Identifie les d√©calages optimaux pour chaque indice.
        
        Returns:
            Dict[str, Dict]: D√©calages optimaux et leurs caract√©ristiques
        """
        print(f"\nüéØ IDENTIFICATION DES D√âCALAGES OPTIMAUX")
        print("-" * 50)
        
        if not self.correlation_results:
            print("‚ùå Corr√©lations non calcul√©es")
            return {}
        
        optimal_lags = {}
        
        for index_name, correlations in self.correlation_results.items():
            if not correlations:
                continue
            
            # Trouver le lag avec la corr√©lation la plus forte (en valeur absolue)
            best_lag = max(correlations.keys(), 
                          key=lambda x: abs(correlations[x]['correlation']))
            
            best_stats = correlations[best_lag]
            
            # Chercher aussi les corr√©lations significatives
            significant_lags = {lag: stats for lag, stats in correlations.items() 
                              if stats['significant']}
            
            optimal_lags[index_name] = {
                'best_lag': best_lag,
                'best_correlation': best_stats['correlation'],
                'best_p_value': best_stats['p_value'],
                'best_n_obs': best_stats['n_obs'],
                'significant_lags': list(significant_lags.keys()),
                'n_significant': len(significant_lags)
            }
            
            print(f"   {index_name}:")
            print(f"     Lag optimal: {best_lag} mois")
            print(f"     Corr√©lation: {best_stats['correlation']:.3f}")
            print(f"     Significativit√©: {'Oui' if best_stats['significant'] else 'Non'} (p={best_stats['p_value']:.3f})")
            print(f"     Lags significatifs: {len(significant_lags)} / {len(correlations)}")
        
        self.best_lags = optimal_lags
        return optimal_lags
    
    def analyze_seasonal_teleconnections(self) -> Dict[str, Dict]:
        """
        Analyse les t√©l√©connexions par saison.
        
        Returns:
            Dict[str, Dict]: Corr√©lations saisonni√®res
        """
        print(f"\nüåç ANALYSE SAISONNI√àRE DES T√âL√âCONNEXIONS")
        print("-" * 50)
        
        if self.monthly_events is None or self.climate_indices is None:
            print("‚ùå Donn√©es non disponibles")
            return {}
        
        # D√©finition des saisons sah√©liennes
        seasons = {
            'saison_seche': [11, 12, 1, 2, 3, 4],  # Nov-Avr
            'saison_pluies': [5, 6, 7, 8, 9, 10]   # Mai-Oct
        }
        
        seasonal_correlations = {}
        
        for season_name, months in seasons.items():
            print(f"   Analyse pour {season_name.replace('_', ' ')}...")
            
            # Filtrage par saison
            season_mask = self.monthly_events.index.month.isin(months)
            events_season = self.monthly_events[season_mask]
            indices_season = self.climate_indices[season_mask]
            
            season_corr = {}
            
            for index_name in self.climate_indices.columns:
                # Utilisation du lag optimal trouv√© pr√©c√©demment
                if index_name in self.best_lags:
                    optimal_lag = self.best_lags[index_name]['best_lag']
                else:
                    optimal_lag = 1  # D√©faut √† 1 mois
                
                # Application du d√©calage
                index_lagged = indices_season[index_name].shift(optimal_lag)
                
                # Alignement et nettoyage
                common_dates = events_season.index.intersection(index_lagged.index)
                events_aligned = events_season.loc[common_dates]
                index_aligned = index_lagged.loc[common_dates]
                
                valid_mask = events_aligned.notna() & index_aligned.notna()
                
                if valid_mask.sum() >= 12:  # Au moins 1 an de donn√©es
                    events_clean = events_aligned[valid_mask]
                    index_clean = index_aligned[valid_mask]
                    
                    corr, p_value = pearsonr(index_clean, events_clean)
                    
                    season_corr[index_name] = {
                        'correlation': corr,
                        'p_value': p_value,
                        'n_obs': len(events_clean),
                        'significant': p_value < 0.05,
                        'lag_used': optimal_lag
                    }
            
            seasonal_correlations[season_name] = season_corr
            
            # Affichage des r√©sultats
            print(f"     Corr√©lations significatives:")
            for idx, stats in season_corr.items():
                if stats['significant']:
                    print(f"       {idx}: {stats['correlation']:.3f} (p={stats['p_value']:.3f})")
        
        return seasonal_correlations
    
    def create_correlation_heatmap(self, max_lag: int = 12, figsize: Tuple[int, int] = (12, 8)):
        """
        Cr√©e une heatmap des corr√©lations par d√©calage temporel.
        
        Args:
            max_lag (int): D√©calage maximum √† afficher
            figsize (tuple): Taille de la figure
        """
        print(f"\nüìä CR√âATION DE LA HEATMAP DES CORR√âLATIONS")
        print("-" * 50)
        
        if not self.correlation_results:
            print("‚ùå Corr√©lations non calcul√©es")
            return
        
        # Pr√©paration des donn√©es pour la heatmap
        correlations_matrix = []
        index_names = []
        lags = list(range(max_lag + 1))
        
        for index_name, correlations in self.correlation_results.items():
            corr_values = []
            for lag in lags:
                if lag in correlations:
                    corr_values.append(correlations[lag]['correlation'])
                else:
                    corr_values.append(np.nan)
            
            correlations_matrix.append(corr_values)
            index_names.append(index_name)
        
        # Conversion en DataFrame pour seaborn
        corr_df = pd.DataFrame(correlations_matrix, 
                              index=index_names, 
                              columns=[f'Lag-{lag}' for lag in lags])
        
        # Cr√©ation de la figure
        fig, ax = plt.subplots(figsize=figsize)
        
        # Heatmap avec masque pour les valeurs manquantes
        mask = corr_df.isnull()
        
        sns.heatmap(corr_df, 
                   annot=True, 
                   fmt='.3f',
                   cmap='RdBu_r',
                   center=0,
                   vmin=-0.5, vmax=0.5,
                   mask=mask,
                   cbar_kws={'label': 'Corr√©lation'},
                   ax=ax)
        
        ax.set_title('Corr√©lations Indices Climatiques - √âv√©nements Extr√™mes\n'
                    'par D√©calage Temporel (S√©n√©gal 1981-2023)', 
                    fontsize=14, fontweight='bold', pad=20)
        ax.set_xlabel('D√©calage Temporel (mois)', fontweight='bold')
        ax.set_ylabel('Indices Climatiques', fontweight='bold')
        
        plt.tight_layout()
        
        # Sauvegarde
        output_path = Path("outputs/visualizations/teleconnections")
        output_path.mkdir(parents=True, exist_ok=True)
        
        plt.savefig(output_path / "correlation_heatmap_lags.png", 
                   dpi=300, bbox_inches='tight')
        print(f"   ‚úÖ Heatmap sauvegard√©e: correlation_heatmap_lags.png")
        
        plt.close()
    
    def create_lag_correlation_plots(self, figsize: Tuple[int, int] = (15, 10)):
        """
        Cr√©e des graphiques d√©taill√©s des corr√©lations par d√©calage.
        
        Args:
            figsize (tuple): Taille de la figure
        """
        print(f"\nüìà CR√âATION DES GRAPHIQUES DE CORR√âLATIONS PAR LAG")
        print("-" * 50)
        
        if not self.correlation_results:
            print("‚ùå Corr√©lations non calcul√©es")
            return
        
        n_indices = len(self.correlation_results)
        fig, axes = plt.subplots(2, 2, figsize=figsize)
        axes = axes.flatten()
        
        for i, (index_name, correlations) in enumerate(self.correlation_results.items()):
            if i >= 4:  # Limitation √† 4 subplots
                break
            
            lags = list(correlations.keys())
            corr_values = [correlations[lag]['correlation'] for lag in lags]
            p_values = [correlations[lag]['p_value'] for lag in lags]
            
            # Graphique des corr√©lations
            axes[i].plot(lags, corr_values, 'o-', linewidth=2, markersize=6, 
                        color='darkblue', label='Corr√©lation')
            
            # Ligne de r√©f√©rence √† z√©ro
            axes[i].axhline(y=0, color='gray', linestyle='--', alpha=0.5)
            
            # Zones de significativit√©
            for j, (lag, p_val) in enumerate(zip(lags, p_values)):
                if p_val < 0.001:
                    axes[i].scatter(lag, corr_values[j], color='red', s=100, marker='*', zorder=5)
                elif p_val < 0.01:
                    axes[i].scatter(lag, corr_values[j], color='orange', s=80, marker='o', zorder=5)
                elif p_val < 0.05:
                    axes[i].scatter(lag, corr_values[j], color='yellow', s=60, marker='o', zorder=5)
            
            # Identification du meilleur lag
            best_lag = max(lags, key=lambda x: abs(correlations[x]['correlation']))
            best_corr = correlations[best_lag]['correlation']
            
            axes[i].scatter(best_lag, best_corr, color='green', s=150, 
                           marker='D', zorder=6, label=f'Optimal (lag-{best_lag})')
            
            axes[i].set_title(f'{index_name}\nMeilleure corr√©lation: {best_corr:.3f} (lag-{best_lag})',
                             fontweight='bold')
            axes[i].set_xlabel('D√©calage (mois)')
            axes[i].set_ylabel('Corr√©lation')
            axes[i].grid(True, alpha=0.3)
            axes[i].legend()
            
            # Limites des axes
            axes[i].set_ylim(-0.6, 0.6)
        
        # Cacher les subplots vides
        for j in range(i + 1, 4):
            axes[j].set_visible(False)
        
        plt.suptitle('Corr√©lations D√©taill√©es par D√©calage Temporel\n'
                    'Indices Climatiques vs √âv√©nements Extr√™mes (S√©n√©gal)',
                    fontsize=16, fontweight='bold', y=0.95)
        
        plt.tight_layout()
        
        # Sauvegarde
        output_path = Path("outputs/visualizations/teleconnections")
        output_path.mkdir(parents=True, exist_ok=True)
        
        plt.savefig(output_path / "detailed_lag_correlations.png", 
                   dpi=300, bbox_inches='tight')
        print(f"   ‚úÖ Graphiques d√©taill√©s sauvegard√©s: detailed_lag_correlations.png")
        
        plt.close()
    
    def create_seasonal_comparison(self, figsize: Tuple[int, int] = (12, 8)):
        """
        Compare les t√©l√©connexions entre saisons.
        
        Args:
            figsize (tuple): Taille de la figure
        """
        print(f"\nüåç CR√âATION DU GRAPHIQUE DE COMPARAISON SAISONNI√àRE")
        print("-" * 50)
        
        # Calcul des corr√©lations saisonni√®res
        seasonal_correlations = self.analyze_seasonal_teleconnections()
        
        if not seasonal_correlations:
            print("‚ùå Corr√©lations saisonni√®res non disponibles")
            return
        
        # Pr√©paration des donn√©es
        indices = list(self.climate_indices.columns)
        seasons = list(seasonal_correlations.keys())
        
        seasonal_data = []
        for season in seasons:
            season_corr = []
            for index in indices:
                if index in seasonal_correlations[season]:
                    corr = seasonal_correlations[season][index]['correlation']
                    season_corr.append(corr)
                else:
                    season_corr.append(0)
            seasonal_data.append(season_corr)
        
        # Cr√©ation du graphique
        x = np.arange(len(indices))
        width = 0.35
        
        fig, ax = plt.subplots(figsize=figsize)
        
        colors = ['#E74C3C', '#27AE60']  # Rouge pour saison s√®che, vert pour pluies
        season_labels = ['Saison S√®che (Nov-Avr)', 'Saison Pluies (Mai-Oct)']
        
        for i, (season_data, color, label) in enumerate(zip(seasonal_data, colors, season_labels)):
            offset = (i - 0.5) * width
            bars = ax.bar(x + offset, season_data, width, label=label, 
                         color=color, alpha=0.8, edgecolor='black', linewidth=0.5)
            
            # Ajout des valeurs sur les barres
            for bar, value in zip(bars, season_data):
                if abs(value) > 0.1:  # Seulement pour les valeurs significatives
                    height = bar.get_height()
                    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01 if height > 0 else height - 0.03,
                           f'{value:.2f}', ha='center', va='bottom' if height > 0 else 'top',
                           fontsize=9, fontweight='bold')
        
        # Configuration du graphique
        ax.set_xlabel('Indices Climatiques', fontweight='bold')
        ax.set_ylabel('Corr√©lation', fontweight='bold')
        ax.set_title('Comparaison Saisonni√®re des T√©l√©connexions\n'
                    'Indices Climatiques vs √âv√©nements Extr√™mes (S√©n√©gal)',
                    fontweight='bold', pad=20)
        ax.set_xticks(x)
        ax.set_xticklabels(indices)
        ax.legend()
        ax.grid(True, alpha=0.3, axis='y')
        ax.axhline(y=0, color='black', linewidth=0.8)
        
        # Limites
        ax.set_ylim(-0.5, 0.5)
        
        plt.tight_layout()
        
        # Sauvegarde
        output_path = Path("outputs/visualizations/teleconnections")
        output_path.mkdir(parents=True, exist_ok=True)
        
        plt.savefig(output_path / "seasonal_teleconnections_comparison.png", 
                   dpi=300, bbox_inches='tight')
        print(f"   ‚úÖ Comparaison saisonni√®re sauvegard√©e: seasonal_teleconnections_comparison.png")
        
        plt.close()
    
    def generate_teleconnections_report(self) -> str:
        """
        G√©n√®re un rapport complet des t√©l√©connexions.
        
        Returns:
            str: Chemin vers le rapport g√©n√©r√©
        """
        print(f"\nüìÑ G√âN√âRATION DU RAPPORT DE T√âL√âCONNEXIONS")
        print("-" * 50)
        
        if not self.correlation_results or not self.best_lags:
            print("‚ùå Analyses non compl√®tes")
            return ""
        
        # Calcul des corr√©lations saisonni√®res
        seasonal_correlations = self.analyze_seasonal_teleconnections()
        
        # Cr√©ation du rapport
        output_dir = Path("outputs/reports")
        output_dir.mkdir(parents=True, exist_ok=True)
        report_path = output_dir / "rapport_teleconnexions.txt"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("RAPPORT D'ANALYSE DES T√âL√âCONNEXIONS\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"Date de g√©n√©ration: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"P√©riode d'analyse: 1981-2023\n")
            f.write(f"Nombre d'√©v√©nements extr√™mes: {self.extreme_events.shape[0] if self.extreme_events is not None else 'N/A'}\n")
            f.write(f"Indices climatiques analys√©s: {list(self.climate_indices.columns)}\n\n")
            
            # Section 1: R√©sultats principaux
            f.write("1. R√âSULTATS PRINCIPAUX\n")
            f.write("-" * 25 + "\n\n")
            
            for index_name, lag_info in self.best_lags.items():
                f.write(f"{index_name}:\n")
                f.write(f"  D√©calage optimal: {lag_info['best_lag']} mois\n")
                f.write(f"  Corr√©lation: {lag_info['best_correlation']:.3f}\n")
                f.write(f"  Significativit√©: {'Oui' if lag_info['best_p_value'] < 0.05 else 'Non'} ")
                f.write(f"(p = {lag_info['best_p_value']:.3f})\n")
                f.write(f"  Nombre d'observations: {lag_info['best_n_obs']}\n")
                f.write(f"  Lags significatifs: {lag_info['n_significant']} lags\n\n")
            
            # Section 2: Analyse saisonni√®re
            f.write("2. ANALYSE SAISONNI√àRE\n")
            f.write("-" * 25 + "\n\n")
            
            for season_name, season_corr in seasonal_correlations.items():
                f.write(f"{season_name.replace('_', ' ').title()}:\n")
                
                significant_correlations = {idx: stats for idx, stats in season_corr.items() 
                                          if stats['significant']}
                
                if significant_correlations:
                    f.write(f"  Corr√©lations significatives:\n")
                    for idx, stats in significant_correlations.items():
                        f.write(f"    {idx}: {stats['correlation']:.3f} (p={stats['p_value']:.3f})\n")
                else:
                    f.write(f"  Aucune corr√©lation significative d√©tect√©e\n")
                f.write("\n")
            
            # Section 3: Interpr√©tation
            f.write("3. INTERPR√âTATION ET M√âCANISMES\n")
            f.write("-" * 35 + "\n\n")
            
            f.write("Indices avec corr√©lations significatives:\n")
            significant_indices = [idx for idx, lag_info in self.best_lags.items() 
                                 if lag_info['best_p_value'] < 0.05]
            
            if significant_indices:
                for idx in significant_indices:
                    lag_info = self.best_lags[idx]
                    f.write(f"  {idx}:\n")
                    f.write(f"    - Corr√©lation {lag_info['best_correlation']:.3f} avec d√©calage de {lag_info['best_lag']} mois\n")
                    
                    if idx == 'IOD':
                        f.write(f"    - M√©canisme: Dip√¥le de l'Oc√©an Indien influence la circulation Walker\n")
                        f.write(f"    - Impact: Modulation des pr√©cipitations via t√©l√©connexions atmosph√©riques\n")
                    elif idx == 'Nino34':
                        f.write(f"    - M√©canisme: ENSO influence la position de la ZCIT\n")
                        f.write(f"    - Impact: Modulation de la mousson ouest-africaine\n")
                    elif idx == 'TNA':
                        f.write(f"    - M√©canisme: Atlantique tropical nord source d'humidit√© directe\n")
                        f.write(f"    - Impact: Contr√¥le du gradient thermique oc√©an-continent\n")
                    f.write("\n")
            else:
                f.write("  Aucune corr√©lation significative d√©tect√©e.\n")
                f.write("  Ceci peut indiquer:\n")
                f.write("    - Relations non-lin√©aires n√©cessitant des approches ML\n")
                f.write("    - Influences locales dominantes\n")
                f.write("    - Besoins d'indices climatiques additionnels\n\n")
            
            # Section 4: Recommandations
            f.write("4. RECOMMANDATIONS POUR LA MOD√âLISATION ML\n")
            f.write("-" * 45 + "\n\n")
            
            f.write("Variables pr√©dictives recommand√©es:\n")
            for idx, lag_info in self.best_lags.items():
                f.write(f"  {idx}_lag{lag_info['best_lag']}: Utiliser avec d√©calage de {lag_info['best_lag']} mois\n")
            
            f.write(f"\nP√©riode d'entra√Ænement sugg√©r√©e: 1981-2017 (37 ans)\n")
            f.write(f"P√©riode de test sugg√©r√©e: 2018-2023 (6 ans)\n\n")
            
            f.write("Algorithmes ML recommand√©s:\n")
            f.write("  - Random Forest: Robuste aux corr√©lations mod√©r√©es\n")
            f.write("  - XGBoost: Capture des interactions non-lin√©aires\n")
            f.write("  - SVM avec noyau RBF: Relations complexes\n")
            f.write("  - R√©seaux de neurones: Patterns sophistiqu√©s\n\n")
        
        print(f"   ‚úÖ Rapport sauvegard√©: {report_path}")
        return str(report_path)
    
    def run_complete_analysis(self, events_file: str, indices_file: str) -> Dict:
        """
        Lance l'analyse compl√®te des t√©l√©connexions.
        
        Args:
            events_file (str): Fichier des √©v√©nements extr√™mes
            indices_file (str): Fichier des indices climatiques
            
        Returns:
            Dict: R√©sum√© des r√©sultats
        """
        print("üåä ANALYSE COMPL√àTE DES T√âL√âCONNEXIONS")
        print("=" * 80)
        
        # Chargement des donn√©es
        if not self.load_extreme_events(events_file).empty:
            print("‚úÖ √âv√©nements extr√™mes charg√©s")
        else:
            print("‚ùå √âchec du chargement des √©v√©nements")
            return {}
        
        if not self.load_climate_indices(indices_file).empty:
            print("‚úÖ Indices climatiques charg√©s")
        else:
            print("‚ùå √âchec du chargement des indices")
            return {}
        
        # Cr√©ation de la s√©rie mensuelle
        self.create_monthly_event_series()
        
        # Calcul des corr√©lations avec d√©calages
        self.calculate_lag_correlations(max_lag=12)
        
        # Identification des d√©calages optimaux
        optimal_lags = self.find_optimal_lags()
        
        # G√©n√©ration des visualisations
        self.create_correlation_heatmap()
        self.create_lag_correlation_plots()
        self.create_seasonal_comparison()
        
        # G√©n√©ration du rapport
        report_path = self.generate_teleconnections_report()
        
        # R√©sum√© final
        print(f"\nüéØ R√âSUM√â DE L'ANALYSE DES T√âL√âCONNEXIONS")
        print("=" * 50)
        
        significant_count = sum(1 for lag_info in optimal_lags.values() 
                              if lag_info['best_p_value'] < 0.05)
        
        print(f"üìä Indices analys√©s: {len(optimal_lags)}")
        print(f"üìä Corr√©lations significatives: {significant_count}/{len(optimal_lags)}")
        print(f"üìä D√©calages optimaux identifi√©s: Oui")
        print(f"üìä Rapport g√©n√©r√©: {report_path}")
        print(f"üìä Visualisations cr√©√©es: 3 fichiers")
        
        return {
            'optimal_lags': optimal_lags,
            'significant_correlations': significant_count,
            'total_indices': len(optimal_lags),
            'report_path': report_path,
            'ready_for_ml': True
        }


if __name__ == "__main__":
    # Test du module
    print("Test du module d'analyse des t√©l√©connexions")
    print("=" * 80)
    
    # Exemple d'utilisation
    analyzer = TeleconnectionsAnalyzer()
    
    # Chemins des fichiers (√† adapter selon votre structure)
    events_file = "data/processed/extreme_events_senegal_final.csv"
    indices_file = "data/processed/climate_indices_combined.csv"
    
    # Analyse compl√®te
    results = analyzer.run_complete_analysis(events_file, indices_file)
    
    if results:
        print(f"\n‚úÖ Analyse termin√©e avec succ√®s!")
        print(f"Pr√™t pour le d√©veloppement des mod√®les ML: {results['ready_for_ml']}")
    else:
        print(f"\n‚ùå √âchec de l'analyse")
    
    print("\n‚úÖ Module test√© avec succ√®s!")
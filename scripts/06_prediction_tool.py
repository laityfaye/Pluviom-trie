#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# scripts/06_prediction_tool.py
"""
Outil de pr√©diction utilisant les mod√®les ML entra√Æn√©s.
Permet de faire des pr√©dictions sur de nouvelles donn√©es climatiques.

Auteur: Analyse Pr√©cipitations Extr√™mes
Date: 2025
"""

import sys
import numpy as np
import pandas as pd
import joblib
import json
from pathlib import Path
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Configuration des chemins
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

class ExtremeEventPredictor:
    """Outil de pr√©diction des √©v√©nements de pr√©cipitations extr√™mes."""
    
    def __init__(self):
        """Initialise le pr√©dicteur."""
        self.models = {}
        self.scaler = None
        self.feature_names = []
        self.metadata = {}
        
        # Chemins
        self.model_dir = project_root / "outputs/models"
        self.data_dir = project_root / "data/processed"
        
    def load_models(self):
        """Charge les mod√®les pr√©-entra√Æn√©s."""
        print("üîÑ CHARGEMENT DES MOD√àLES PR√â-ENTRA√éN√âS")
        print("=" * 50)
        
        try:
            # Charger le scaler
            scaler_path = self.model_dir / "feature_scaler.pkl"
            if scaler_path.exists():
                self.scaler = joblib.load(scaler_path)
                print("‚úÖ Scaler charg√©")
            else:
                print("‚ùå Scaler non trouv√©")
                return False
            
            # Charger les m√©tadonn√©es
            metadata_path = project_root / "outputs/data/ml_results_summary.json"
            if metadata_path.exists():
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    self.metadata = json.load(f)
                print("‚úÖ M√©tadonn√©es charg√©es")
            
            # Chercher et charger les mod√®les disponibles
            model_files = list(self.model_dir.glob("*.pkl"))
            model_files = [f for f in model_files if f.name != "feature_scaler.pkl"]
            
            for model_file in model_files:
                try:
                    model = joblib.load(model_file)
                    model_name = model_file.stem
                    self.models[model_name] = model
                    print(f"‚úÖ Mod√®le charg√©: {model_name}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erreur chargement {model_file.name}: {e}")
            
            if not self.models:
                print("‚ùå Aucun mod√®le trouv√©")
                return False
            
            # Charger les noms des features depuis le dataset ML
            ml_dataset_path = self.data_dir / "ml_dataset_teleconnections.csv"
            if ml_dataset_path.exists():
                sample_data = pd.read_csv(ml_dataset_path, nrows=1)
                target_cols = ['occurrence', 'count', 'intensity']
                self.feature_names = [col for col in sample_data.columns if col not in target_cols]
                print(f"‚úÖ Features identifi√©es: {len(self.feature_names)} variables")
            
            print(f"\nüìä MOD√àLES DISPONIBLES:")
            for name in self.models.keys():
                model_type = "Classification" if "classifier" in name else "R√©gression"
                print(f"   ‚Ä¢ {name}: {model_type}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement: {e}")
            return False
    
    def create_sample_input(self):
        """Cr√©e un exemple d'entr√©e bas√© sur les donn√©es historiques."""
        print("\nüìã CR√âATION D'UN EXEMPLE D'ENTR√âE")
        print("=" * 50)
        
        try:
            # Charger un √©chantillon du dataset
            ml_dataset_path = self.data_dir / "ml_dataset_teleconnections.csv"
            if not ml_dataset_path.exists():
                print("‚ùå Dataset ML non trouv√©")
                return None
            
            df = pd.read_csv(ml_dataset_path, index_col=0, parse_dates=True)
            
            # Prendre les donn√©es du mois le plus r√©cent
            latest_data = df.iloc[-1]
            
            # Extraire seulement les features
            sample_input = latest_data[self.feature_names].to_dict()
            
            print("‚úÖ Exemple d'entr√©e cr√©√© bas√© sur les donn√©es les plus r√©centes")
            print(f"   Date de r√©f√©rence: {df.index[-1]}")
            print(f"   Nombre de features: {len(sample_input)}")
            
            # Afficher quelques features importantes
            print(f"\nüìä APER√áU DES FEATURES:")
            for i, (feature, value) in enumerate(list(sample_input.items())[:10]):
                print(f"   {feature}: {value:.3f}")
            if len(sample_input) > 10:
                print(f"   ... et {len(sample_input) - 10} autres features")
            
            return sample_input
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la cr√©ation: {e}")
            return None
    
    def predict_from_features(self, features_dict):
        """Fait des pr√©dictions √† partir d'un dictionnaire de features."""
        print(f"\nüîÆ PR√âDICTIONS √Ä PARTIR DES FEATURES")
        print("=" * 50)
        
        try:
            # Convertir en DataFrame
            features_df = pd.DataFrame([features_dict])
            
            # V√©rifier que toutes les features sont pr√©sentes
            missing_features = set(self.feature_names) - set(features_df.columns)
            if missing_features:
                print(f"‚ö†Ô∏è  Features manquantes: {len(missing_features)} features")
                # Ajouter des valeurs par d√©faut (0) pour les features manquantes
                for feature in missing_features:
                    features_df[feature] = 0
            
            # R√©organiser les colonnes selon l'ordre attendu
            features_df = features_df[self.feature_names]
            
            # Normaliser avec le scaler
            features_scaled = self.scaler.transform(features_df)
            
            print(f"‚úÖ Features pr√©par√©es et normalis√©es")
            
            # Faire les pr√©dictions avec tous les mod√®les
            predictions = {}
            
            for model_name, model in self.models.items():
                try:
                    if "classifier" in model_name:
                        # Pr√©diction de classification (occurrence)
                        prob = model.predict_proba(features_scaled)[0, 1]
                        pred = model.predict(features_scaled)[0]
                        
                        predictions[model_name] = {
                            'type': 'classification',
                            'prediction': bool(pred),
                            'probability': float(prob),
                            'confidence': '√âlev√©e' if abs(prob - 0.5) > 0.3 else 'Mod√©r√©e'
                        }
                        
                    elif "regressor" in model_name:
                        # Pr√©diction de r√©gression (intensit√©)
                        intensity = model.predict(features_scaled)[0]
                        
                        predictions[model_name] = {
                            'type': 'regression',
                            'predicted_intensity': float(max(0, intensity)),  # Pas d'intensit√© n√©gative
                            'unit': 'mm/jour'
                        }
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erreur avec {model_name}: {e}")
                    continue
            
            return predictions
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la pr√©diction: {e}")
            return {}
    
    def predict_from_climate_indices(self, iod=0, nino34=0, tna=0, month=None):
        """Fait des pr√©dictions √† partir des indices climatiques principaux."""
        print(f"\nüåä PR√âDICTION √Ä PARTIR DES INDICES CLIMATIQUES")
        print("=" * 50)
        
        if month is None:
            month = datetime.now().month
        
        print(f"üìä Indices climatiques:")
        print(f"   IOD: {iod:.3f}")
        print(f"   Nino34: {nino34:.3f}")
        print(f"   TNA: {tna:.3f}")
        print(f"   Mois: {month}")
        
        # Cr√©er un dictionnaire de features simplifi√©
        # En pratique, on devrait avoir tous les lags, mais on simplifie ici
        features_dict = {}
        
        # Ajouter les indices principaux (lag 0)
        features_dict['IOD_lag0'] = iod
        features_dict['Nino34_lag0'] = nino34
        features_dict['TNA_lag0'] = tna
        
        # Ajouter quelques lags importants (on utilise les m√™mes valeurs par simplicit√©)
        for lag in range(1, 13):
            features_dict[f'IOD_lag{lag}'] = iod * (0.9**lag)  # D√©croissance artificielle
            features_dict[f'Nino34_lag{lag}'] = nino34 * (0.9**lag)
            features_dict[f'TNA_lag{lag}'] = tna * (0.9**lag)
        
        # Ajouter les features temporelles
        features_dict['month'] = month
        features_dict['season'] = 1 if month in [5, 6, 7, 8, 9, 10] else 0  # Saison des pluies
        
        # Compl√©ter avec des z√©ros pour les features manquantes
        for feature in self.feature_names:
            if feature not in features_dict:
                features_dict[feature] = 0
        
        return self.predict_from_features(features_dict)
    
    def display_predictions(self, predictions):
        """Affiche les pr√©dictions de mani√®re format√©e."""
        print(f"\nüéØ R√âSULTATS DES PR√âDICTIONS")
        print("=" * 50)
        
        if not predictions:
            print("‚ùå Aucune pr√©diction disponible")
            return
        
        # S√©parer classification et r√©gression
        classification_results = {k: v for k, v in predictions.items() if v['type'] == 'classification'}
        regression_results = {k: v for k, v in predictions.items() if v['type'] == 'regression'}
        
        # Afficher les r√©sultats de classification
        if classification_results:
            print("üéØ CLASSIFICATION (Occurrence d'√©v√©nements):")
            print("-" * 40)
            
            for model_name, result in classification_results.items():
                model_display = model_name.replace('_classifier', '').replace('_', ' ').title()
                status = "üî¥ √âV√âNEMENT PR√âDIT" if result['prediction'] else "üü¢ PAS D'√âV√âNEMENT"
                
                print(f"   {model_display}:")
                print(f"     ‚Ä¢ Pr√©diction: {status}")
                print(f"     ‚Ä¢ Probabilit√©: {result['probability']:.1%}")
                print(f"     ‚Ä¢ Confiance: {result['confidence']}")
                print()
        
        # Afficher les r√©sultats de r√©gression
        if regression_results:
            print("üìä R√âGRESSION (Intensit√© pr√©dite):")
            print("-" * 35)
            
            for model_name, result in regression_results.items():
                model_display = model_name.replace('_regressor', '').replace('_', ' ').title()
                intensity = result['predicted_intensity']
                
                # Cat√©goriser l'intensit√©
                if intensity < 10:
                    category = "Faible"
                    color = "üü¢"
                elif intensity < 30:
                    category = "Mod√©r√©e"
                    color = "üü°"
                elif intensity < 50:
                    category = "Forte"
                    color = "üü†"
                else:
                    category = "Tr√®s forte"
                    color = "üî¥"
                
                print(f"   {model_display}:")
                print(f"     ‚Ä¢ Intensit√©: {intensity:.1f} {result['unit']}")
                print(f"     ‚Ä¢ Cat√©gorie: {color} {category}")
                print()
        
        # Synth√®se et recommandations
        print("üìã SYNTH√àSE ET RECOMMANDATIONS:")
        print("-" * 35)
        
        # Consensus des mod√®les de classification
        if classification_results:
            predictions_positive = sum(1 for r in classification_results.values() if r['prediction'])
            consensus_prob = np.mean([r['probability'] for r in classification_results.values()])
            
            if predictions_positive > len(classification_results) / 2:
                print("   üî¥ RISQUE √âLEV√â: Majorit√© des mod√®les pr√©disent un √©v√©nement")
                print("   üí° Recommandation: Surveillance renforc√©e conseill√©e")
            else:
                print("   üü¢ RISQUE FAIBLE: Majorit√© des mod√®les ne pr√©disent pas d'√©v√©nement")
                print("   üí° Recommandation: Surveillance normale")
            
            print(f"   üìä Probabilit√© moyenne: {consensus_prob:.1%}")
        
        # Intensit√© maximale pr√©dite
        if regression_results:
            max_intensity = max(r['predicted_intensity'] for r in regression_results.values())
            print(f"   üåßÔ∏è  Intensit√© maximale pr√©dite: {max_intensity:.1f} mm/jour")
            
            if max_intensity > 50:
                print("   ‚ö†Ô∏è  Intensit√© potentiellement dangereuse")
            elif max_intensity > 20:
                print("   ‚ö° Intensit√© significative possible")
    
    def interactive_prediction(self):
        """Mode interactif pour les pr√©dictions."""
        print(f"\nüîÆ MODE PR√âDICTION INTERACTIF")
        print("=" * 50)
        
        while True:
            print(f"\nOPTIONS DISPONIBLES:")
            print("1. Pr√©diction avec indices climatiques simplifi√©s")
            print("2. Pr√©diction avec exemple bas√© sur donn√©es historiques")
            print("3. Quitter")
            
            try:
                choice = input("\nVotre choix (1-3): ").strip()
                
                if choice == "1":
                    print(f"\nüìä SAISIE DES INDICES CLIMATIQUES:")
                    try:
                        iod = float(input("IOD (Indian Ocean Dipole, ex: -0.5 √† 1.0): ") or "0")
                        nino34 = float(input("Nino34 (ENSO, ex: -2.0 √† 2.0): ") or "0")
                        tna = float(input("TNA (Tropical North Atlantic, ex: -1.0 √† 1.0): ") or "0")
                        month = int(input("Mois (1-12): ") or str(datetime.now().month))
                        
                        predictions = self.predict_from_climate_indices(iod, nino34, tna, month)
                        self.display_predictions(predictions)
                        
                    except ValueError:
                        print("‚ùå Valeurs invalides, veuillez r√©essayer")
                
                elif choice == "2":
                    sample_input = self.create_sample_input()
                    if sample_input:
                        predictions = self.predict_from_features(sample_input)
                        self.display_predictions(predictions)
                
                elif choice == "3":
                    print("üëã Au revoir!")
                    break
                
                else:
                    print("‚ùå Choix invalide")
                    
            except KeyboardInterrupt:
                print("\nüëã Au revoir!")
                break
    
    def run_prediction_tool(self):
        """Lance l'outil de pr√©diction."""
        print("üîÆ OUTIL DE PR√âDICTION - √âV√âNEMENTS EXTR√äMES")
        print("=" * 70)
        print("Utilise les mod√®les ML entra√Æn√©s pour pr√©dire les pr√©cipitations extr√™mes")
        print("=" * 70)
        
        # Charger les mod√®les
        if not self.load_models():
            print("‚ùå Impossible de charger les mod√®les")
            return False
        
        # Afficher les informations des mod√®les
        if self.metadata:
            print(f"\nüìä INFORMATIONS DES MOD√àLES:")
            if 'data_info' in self.metadata:
                data_info = self.metadata['data_info']
                print(f"   ‚Ä¢ P√©riode d'entra√Ænement: {data_info.get('train_period', 'N/A')}")
                print(f"   ‚Ä¢ P√©riode de test: {data_info.get('test_period', 'N/A')}")
                print(f"   ‚Ä¢ Nombre de features: {data_info.get('n_features', 'N/A')}")
            
            # Meilleur mod√®le de classification
            if 'classification_results' in self.metadata:
                best_classifier = max(
                    self.metadata['classification_results'].items(),
                    key=lambda x: x[1]['test_f1']
                )
                print(f"   ‚Ä¢ Meilleur classificateur: {best_classifier[0]} (F1: {best_classifier[1]['test_f1']:.3f})")
            
            # Meilleur mod√®le de r√©gression
            if 'regression_results' in self.metadata:
                best_regressor = max(
                    self.metadata['regression_results'].items(),
                    key=lambda x: x[1]['test_r2']
                )
                print(f"   ‚Ä¢ Meilleur r√©gresseur: {best_regressor[0]} (R¬≤: {best_regressor[1]['test_r2']:.3f})")
        
        # Lancer le mode interactif
        self.interactive_prediction()
        
        return True

def main():
    """Fonction principale."""
    print("üîÆ OUTIL DE PR√âDICTION ML - PR√âCIPITATIONS EXTR√äMES")
    print("=" * 70)
    
    predictor = ExtremeEventPredictor()
    success = predictor.run_prediction_tool()
    
    if success:
        print("\n‚úÖ OUTIL DE PR√âDICTION TERMIN√â")
        print("\nüí° UTILISATION RECOMMAND√âE:")
        print("‚Ä¢ Int√©grez cet outil dans un syst√®me de monitoring")
        print("‚Ä¢ Utilisez les pr√©dictions pour l'alerte pr√©coce")
        print("‚Ä¢ Validez les pr√©dictions avec les observations")
        print("‚Ä¢ Mettez √† jour les mod√®les r√©guli√®rement")
        return 0
    else:
        print("\n‚ùå √âCHEC DE L'OUTIL DE PR√âDICTION")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)